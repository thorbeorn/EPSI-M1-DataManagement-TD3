# EPSI-M1-DataManagement-TD3

## TD 3 : Validation qualitÃ©

Pipeline ETL (Extract, Transform, Load) avec validation de qualitÃ© des donnÃ©es utilisant Pandas et Pandera.

---

## ğŸ¯ Objectifs pÃ©dagogiques

- Comprendre les principes d'un pipeline ETL
- MaÃ®triser la validation de donnÃ©es avec Pandera
- ImplÃ©menter des transformations de donnÃ©es robustes
- GÃ©rer les erreurs et la qualitÃ© des donnÃ©es
- Mettre en place des tests unitaires avec Pytest
- SÃ©parer les donnÃ©es valides des donnÃ©es invalides

---

## ğŸ“ Structure gÃ©nÃ©rale du TD

```
TD3/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ users_raw.csv
â”‚   â”œâ”€â”€ trusted/
â”‚   â”‚   â””â”€â”€ dylan_YYYYMMDD_HHMMSS.parquet
â”‚   â”œâ”€â”€ quarantine/
â”‚   â”‚   â””â”€â”€ dylan_YYYYMMDD_HHMMSS.parquet
â”‚   â””â”€â”€ alerts/
â”‚       â”œâ”€â”€ alert_YYYYMMDD_HHMMSS.txt
â”‚       â””â”€â”€ alert_YYYYMMDD_HHMMSS.json
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_etl_functions.py
â”œâ”€â”€ etl_pipeline.py
â””â”€â”€ README.md
```

---

## ğŸ“ Description

### Objectif

Ce projet implÃ©mente un pipeline ETL complet qui :

1. **Extrait** les donnÃ©es depuis un fichier CSV
2. **Transforme** les donnÃ©es (normalisation, conversion de types)
3. **Valide** la qualitÃ© des donnÃ©es avec des rÃ¨gles mÃ©tier
4. **Charge** les donnÃ©es dans deux destinations :
   - **Trusted** : DonnÃ©es valides au format Parquet
   - **Quarantine** : DonnÃ©es invalides pour analyse

### FonctionnalitÃ©s principales

#### ğŸ”„ Extraction
- Lecture de fichiers CSV
- Gestion des erreurs de lecture

#### ğŸ”§ Transformation
- Conversion en minuscules (`username`, `email`)
- Conversion numÃ©rique (`user_id`, `age`)
- Conversion de dates (`signup_date`)
- Remplacement des valeurs invalides par `pd.NA` ou `NaT`

#### âœ… Validation
Les rÃ¨gles de validation appliquÃ©es :

| Colonne | Type | Contraintes |
|---------|------|-------------|
| `user_id` | Int64 | Unique, Non-null |
| `username` | String | Non-null |
| `email` | String | Format email valide, Non-null |
| `age` | Int64 | Entre -20 et 100, Non-null |
| `signup_date` | Datetime | Non-null |

#### ğŸ“Š SÃ©paration des donnÃ©es
- **DonnÃ©es valides** â†’ `data/trusted/`
- **DonnÃ©es invalides** â†’ `data/quarantine/`
- **Alertes** â†’ `data/alerts/` (formats TXT et JSON)

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.12+**
- **Pandas** : Manipulation de donnÃ©es
- **Pandera** : Validation de schÃ©mas de donnÃ©es
- **PyArrow** : Export Parquet
- **Pytest** : Tests unitaires

---

## ğŸ“¦ Installation gÃ©nÃ©rale

### PrÃ©requis

- Python 3.12 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Installer les dÃ©pendances

```bash
# Cloner le projet
cd TD3

# CrÃ©er un environnement virtuel (recommandÃ©)
python3 -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install pandas pandera pyarrow pytest
```

### Structure des dÃ©pendances

```txt
pandas>=2.0.0
pandera>=0.17.0
pyarrow>=14.0.0
pytest>=7.0.0
```

---

## ğŸš€ ExÃ©cution

### ExÃ©cuter le pipeline ETL

```bash
python3 etl_pipeline.py
```

### Sortie attendue (succÃ¨s)

```
Data extraction successful.
Data transformation successful.
Data Quality Check Passed. Pipeline finished successfully.
```

### Sortie attendue (Ã©chec avec donnÃ©es invalides)

```
Data extraction successful.
Data transformation successful.
[DÃ©tails des erreurs de validation]
ON VIOLATION
```

### ExÃ©cuter les tests unitaires

```bash
# ExÃ©cuter tous les tests
pytest

# ExÃ©cuter avec dÃ©tails
pytest -v

# ExÃ©cuter un test spÃ©cifique
pytest tests/test_etl_functions.py::test_transform_data_valid_input

# ExÃ©cuter avec couverture de code
pytest --cov=etl_pipeline
```

---

## ğŸ“š Documentation des fonctions

### `extract_Dataframe_From_CSV(path)`
Extrait les donnÃ©es d'un fichier CSV.

**ParamÃ¨tres :**
- `path` (str) : Chemin vers le fichier CSV

**Retourne :** DataFrame pandas

---

### `lowercase_Dataframe_Column(dataframe, column)`
Convertit une colonne en minuscules et remplace les chaÃ®nes vides par `pd.NA`.

**ParamÃ¨tres :**
- `dataframe` (pd.DataFrame) : DataFrame source
- `column` (str) : Nom de la colonne Ã  transformer

**Retourne :** DataFrame modifiÃ©

---

### `replace_Dataframe_Column_Not_Numeric_To_NULL(dataframe, column)`
Convertit une colonne en numÃ©rique (Int64), les valeurs non-numÃ©riques deviennent `pd.NA`.

**ParamÃ¨tres :**
- `dataframe` (pd.DataFrame) : DataFrame source
- `column` (str) : Nom de la colonne Ã  transformer

**Retourne :** DataFrame modifiÃ©

---

### `replace_Dataframe_Column_Not_Datetime_To_NULL(dataframe, column)`
Convertit une colonne en datetime, les valeurs invalides deviennent `NaT`.

**ParamÃ¨tres :**
- `dataframe` (pd.DataFrame) : DataFrame source
- `column` (str) : Nom de la colonne Ã  transformer

**Retourne :** DataFrame modifiÃ©

---

### `transform_data(dataframe)`
Applique toutes les transformations sur le DataFrame.

**Transformations appliquÃ©es :**
1. Conversion numÃ©rique de `user_id` et `age`
2. Conversion en minuscules de `username` et `email`
3. Conversion datetime de `signup_date`

**Retourne :** DataFrame transformÃ©

---

### `validate_data(dataframe)`
Valide les donnÃ©es selon le schÃ©ma Pandera dÃ©fini.

**Retourne :**
- `valid_dataframe` : DonnÃ©es valides
- `failed_dataframe` : DonnÃ©es invalides
- `exception_error` : DÃ©tails des erreurs (ou None)

---

## ğŸ“ CompÃ©tences acquises

### Techniques
- âœ… Conception et implÃ©mentation d'un pipeline ETL
- âœ… Validation de donnÃ©es avec Pandera
- âœ… Gestion des types nullable (Int64, string)
- âœ… Manipulation avancÃ©e de DataFrames Pandas
- âœ… Export au format Parquet
- âœ… Tests unitaires avec Pytest

### Bonnes pratiques
- âœ… SÃ©paration des prÃ©occupations (Extract/Transform/Validate)
- âœ… Gestion des erreurs et exceptions
- âœ… Logging et alertes
- âœ… Tests unitaires complets
- âœ… Documentation du code

### QualitÃ© des donnÃ©es
- âœ… DÃ©finition de rÃ¨gles de validation
- âœ… SÃ©paration donnÃ©es valides/invalides
- âœ… TraÃ§abilitÃ© des erreurs
- âœ… Gestion des valeurs manquantes

---

## ğŸ“Š Exemple de flux de donnÃ©es

```
users_raw.csv
     â†“
[EXTRACTION]
     â†“
DataFrame brut
     â†“
[TRANSFORMATION]
- Normalisation texte
- Conversion types
- Gestion valeurs nulles
     â†“
DataFrame transformÃ©
     â†“
[VALIDATION]
     â†“
   â†™     â†˜
VALIDE   INVALIDE
  â†“         â†“
trusted/  quarantine/
```

---

## ğŸ› Gestion des erreurs

### Types d'erreurs dÃ©tectÃ©es

1. **Duplicatas** : `user_id` dupliquÃ©s
2. **Valeurs manquantes** : Colonnes obligatoires nulles
3. **Formats invalides** : Emails malformÃ©s
4. **Valeurs hors limites** : Age < -20 ou > 100
5. **Types incompatibles** : Dates/nombres invalides

### Fichiers d'alerte

Les erreurs gÃ©nÃ¨rent deux fichiers :

**alert_YYYYMMDD_HHMMSS.txt**
```
CRITICAL: ETL Pipeline failed for users_raw.csv. See json for details.
```

**alert_YYYYMMDD_HHMMSS.json**
```json
{
  "DATA": {
    "SERIES_CONTAINS_DUPLICATES": [...],
    "DATAFRAME_CHECK": [...]
  }
}
```

---

## ğŸ§ª Tests unitaires

Le projet contient 13 tests couvrant :

- Transformation en minuscules
- Conversion numÃ©rique avec gestion d'erreurs
- Conversion datetime avec gestion d'erreurs
- Transformation complÃ¨te du DataFrame
- Validation des entrÃ©es
- PrÃ©servation de la structure des donnÃ©es
- Gestion des cas limites

**ExÃ©cution des tests :**
```bash
pytest -v
```

---

## ğŸ“„ Licence

Projet libre d'utilisation et de modification â€” **usage pÃ©dagogique EPSI**.

---

## ğŸ‘¨â€ğŸ’» Auteur

Dylan LLODRA - M1 Data Management - EPSI

---

## ğŸ“ Support

Pour toute question concernant ce TD :
- Consulter la documentation Pandera : https://pandera.readthedocs.io/
- Consulter la documentation Pandas : https://pandas.pydata.org/docs/